/**
 * Vercel Serverless Function ‚Äî Chat com GPT-5.3
 * Proxy SSE streaming para a API OpenAI.
 *
 * O frontend envia: { messages: [{ role, content }] }
 * A fun√ß√£o injeta o system prompt do Axiom e retransmite o streaming SSE.
 */

const OPENAI_API_URL = 'https://api.openai.com/v1/chat/completions';
const MODEL = 'gpt-5.3';

const AXIOM_SYSTEM_PROMPT = `Voc√™ √© **Axiom**, um estrategista de vida conversacional integrado ao App Axiom. Voc√™ ajuda o usu√°rio a organizar e otimizar sua vida atrav√©s de conversa natural.

## Suas capacidades:
- üí∞ **Finan√ßas**: Analisar transa√ß√µes, contas, parcelamentos, assinaturas. Dar insights sobre gastos e economia.
- üéØ **H√°bitos**: Acompanhar streaks, sugerir novos h√°bitos, motivar consist√™ncia.
- ‚úÖ **Tarefas**: Organizar tarefas, sugerir prioridades, acompanhar deadlines.
- üìù **Mem√≥ria**: Guardar notas, reflex√µes, e usar contexto de conversas anteriores.
- üìä **An√°lises**: Gerar insights do Axiom Score (nota geral de organiza√ß√£o de vida).

## Regras:
- Responda SEMPRE em portugu√™s do Brasil.
- Seja direto, emp√°tico e acion√°vel.
- Use emojis com modera√ß√£o (1-2 por mensagem m√°ximo).
- Respostas devem ser curtas (2-4 par√°grafos m√°ximo).
- Quando o usu√°rio pedir para criar algo (tarefa, transa√ß√£o, h√°bito), sugira a a√ß√£o e confirme com ele.
- Voc√™ N√ÉO inventa dados financeiros ‚Äî use apenas o que o usu√°rio informou.
- Se n√£o souber algo, admita e sugira como o usu√°rio pode registrar a informa√ß√£o.

## Tom de voz:
Voc√™ √© como um coach pessoal inteligente e amig√°vel. Pense em um mix de consultor financeiro + coach de h√°bitos + assistente pessoal. Nunca seja rob√≥tico ou gen√©rico.`;

export const config = {
    runtime: 'edge',
};

export default async function handler(request: Request): Promise<Response> {
    // Apenas POST
    if (request.method !== 'POST') {
        return new Response(JSON.stringify({ error: 'Method not allowed' }), {
            status: 405,
            headers: { 'Content-Type': 'application/json' },
        });
    }

    const apiKey = process.env.OPENAI_API_KEY;
    if (!apiKey) {
        return new Response(
            JSON.stringify({ error: 'OPENAI_API_KEY n√£o configurada no servidor' }),
            { status: 500, headers: { 'Content-Type': 'application/json' } }
        );
    }

    try {
        const body = await request.json();
        const userMessages = body.messages || [];

        // Montar mensagens com system prompt
        const messages = [
            { role: 'system', content: AXIOM_SYSTEM_PROMPT },
            ...userMessages,
        ];

        // Chamar OpenAI com streaming
        const openaiResponse = await fetch(OPENAI_API_URL, {
            method: 'POST',
            headers: {
                'Content-Type': 'application/json',
                Authorization: `Bearer ${apiKey}`,
            },
            body: JSON.stringify({
                model: MODEL,
                messages,
                stream: true,
                temperature: 0.7,
                max_tokens: 2048,
            }),
        });

        if (!openaiResponse.ok) {
            const errorText = await openaiResponse.text();
            console.error('OpenAI API error:', openaiResponse.status, errorText);
            return new Response(
                JSON.stringify({
                    error: `Erro na API OpenAI: ${openaiResponse.status}`,
                    details: errorText,
                }),
                { status: openaiResponse.status, headers: { 'Content-Type': 'application/json' } }
            );
        }

        // Retransmitir o streaming SSE diretamente
        return new Response(openaiResponse.body, {
            status: 200,
            headers: {
                'Content-Type': 'text/event-stream',
                'Cache-Control': 'no-cache',
                Connection: 'keep-alive',
                'X-Accel-Buffering': 'no',
            },
        });
    } catch (error) {
        console.error('Chat handler error:', error);
        return new Response(
            JSON.stringify({
                error: error instanceof Error ? error.message : 'Erro interno do servidor',
            }),
            { status: 500, headers: { 'Content-Type': 'application/json' } }
        );
    }
}
